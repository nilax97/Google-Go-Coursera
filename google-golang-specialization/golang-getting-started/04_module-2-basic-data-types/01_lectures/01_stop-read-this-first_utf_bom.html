<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Content-Language" content="en-us">
<meta name="VI60_defaultClientScript" content="JavaScript">
<meta name="GENERATOR" content="Microsoft FrontPage 12.0">
<meta name="keywords" content="utf, bom">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>FAQ - UTF-8, UTF-16, UTF-32 &amp; BOM</title>
<link rel="stylesheet" type="text/css" 
href="http://www.unicode.org/webscripts/standard_styles.css">
<link rel="stylesheet" type="text/css" href="faq_styles.css">
<style type="text/css">
<!--
/* moved to faq_styles.css */
-->
</style>

</head>

<body text="#330000">

  <table width="100%" cellpadding="0" cellspacing="0" border="0">
    <tr>
      <td colspan="2">
      <table width="100%" border="0" cellpadding="0" cellspacing="0">
        <tr>
<!-- new style header, which lines up left and right -->
					<td class="icon" style="width:38px; height:35px"><a href="http://www.unicode.org/"><img border="0"
					src="http://www.unicode.org/webscripts/logo60s2.gif" align="middle"
					alt="[Unicode]" width="34" height="33"></a></td>
					<td class="icon" style="vertical-align:middle;">
<!-- old style header, with misaligned items left/right 
        <td class="icon"><a href="http://www.unicode.org/"><img border="0"
        src="http://www.unicode.org/webscripts/logo60s2.gif" align="middle"
        alt="[Unicode]" width="34" height="33"></a>
        &nbsp; -->
        &nbsp;<a class="bar" 
          href="http://www.unicode.org/unicode/faq/"><font size="3">Frequently    
          Asked Questions</font></a></td>   
          <td class="bar"><a href="http://www.unicode.org" class="bar">Home</a> 
          | <a href="http://www.unicode.org/sitemap/" class="bar">Site Map</a> | 
          <a href="http://www.unicode.org/search/" class="bar">Search </a></td>
        </tr>
      </table>
      </td>
    </tr>
  </table>
  <!-- BEGIN CONTENTS -->
  <table>
    <tr>
      <td class="contents" valign="top">
      <blockquote>
        <h1>UTF-8, UTF-16, UTF-32 &amp; BOM</h1> 
	      <div class="faqtoc" style="max-width:33%">
	        <h2><a href="#General">General questions, relating to UTF or Encoding Forms</a></h2>
	        <ul class="faq">
	          <li><a href="#gen0">Is Unicode a 16-bit encoding?</a></li>
			  <li><a href="#gen1">Can Unicode text be represented in more than one way?</a></li>
	          <li><a href="#gen2">What is a UTF?</a></li>
	          <li><a href="#gen3">Where can I get more information on encoding forms?</a></li>
			  <li><a href="#gen4">How do I write a UTF converter?</a></li>
	          <li><a href="#gen5">Which of the UTFs do I need to support?</a></li>
		      <li><a href="#gen6">What are some of the differences between the UTFs?</a></li>
	          <li><a href="#gen7">Why do some UTFs have a BE or LE in their label, as in UTF-16LE?</a></li>
	          <li><a href="#gen8">Are there any byte sequences that are not generated by a UTF? How should I interpret them?</a></li>
	          <li><a href="#gen9">Is there a standard method to package a Unicode character so it fits an 8-Bit ASCII stream?</a></li>
			  <li><a href="#gen10">Which of these approaches is the best?</a></li>
			  <li><a href="#gen11">Which of these formats is the most standard?</a></li>
	        </ul>
			<h2><a href="#UTF8">UTF-8 FAQ</a></h2>
			<ul class="faq">
	          <li><a href="#utf8-1">What is the definition of UTF-8?</a></li>
	          <li><a href="#utf8-2">Is the UTF-8 encoding scheme the same irrespective of whether the underlying processor is little endian or big endian?</a></li>
	          <li><a href="#utf8-3">Is the UTF-8 encoding scheme the same irrespective of whether the underlying system uses ASCII or EBCDIC encoding?</a></li>
	          <li><a href="#utf8-4">How do I convert a UTF-16 surrogate pair such as &lt;D800 DC00&gt; to UTF-8? As one 4-byte sequence or as two separate 3-byte sequences?</a></li>
			  <li><a href="#utf8-5">How do I convert an unpaired UTF-16 surrogate to UTF-8?</a> </li>
	        </ul>
			<h2><a href="#UTF16">UTF-16 FAQ</a></h2>
			<ul class="faq">
	          <li><a href="#utf16-1">What is UTF-16?</a></li>
			  <li><a href="#utf16-2">What are surrogates?</a></li>
			  <li><a href="#utf16-3">What is the algorithm to convert from UTF-16 to character codes?</a></li>
			  <li><a href="#utf16-4">Isn’t there a simpler way to do this?</a></li>
	          <li><a href="#utf16-5">Why are some people opposed to UTF-16?</a></li>
	          <li><a href="#utf16-6">Will UTF-16 ever be extended to more than a million characters?</a></li>
	          <li><a href="#utf16-7">Are there any 16-bit values that are invalid?</a></li>
			  <li><a href="#utf16-8">What about noncharacters? Are they invalid?</a></li>
	          <li><a href="#utf16-9">Because most supplementary characters are uncommon, does that mean I can ignore them?</a></li>
              <li><a href="#utf16-10">How should I handle supplementary characters in my code?</a></li>
			  <li><a href="#utf16-11">What is the difference between UCS-2 and UTF-16?</a></li>
	        </ul>
			<h2><a href="#UTF32">UTF-32 FAQ</a></h2>
			<ul class="faq">
	          <li><a href="#utf32-1">What is UTF-32?</a></li>
			  <li><a href="#utf32-2">Should I use UTF-32 (or UCS-4) for storing Unicode strings in memory?</a></li>
	          <li><a href="#utf32-3">How about using UTF-32 interfaces in my APIs?</a></li>
	          <li><a href="#utf32-4">Doesn’t it cause a problem to have UTF-16 string APIs, instead of UTF-32 char APIs?</a></li>
			  <li><a href="#utf32-5">Are there exceptions to the rule of exclusively using string parameters in APIs?</a></li>
			  <li><a href="#utf32-6">How do I convert a UTF-16 surrogate pair such as &lt;D800 DC00&gt; to UTF-32? As one or as two	4-byte sequences?</a></li>
			  <li><a href="#utf32-7">How do I convert an unpaired UTF-16 surrogate to UTF-32?</a> </li>
	        </ul>
			<h2><a href="#BOM">Byte Order Mark (BOM) FAQ</a></h2>
			<ul class="faq">
	          <li><a href="#bom1">What is a BOM?</a></li>
	          <li><a href="#bom2">Where is a BOM Useful?</a></li>
			  <li><a href="#bom3">What does &#x2018;endian&#x2019; mean?</a></li>
			  <li><a href="#bom4">When a BOM is used, is it only in 16-bit Unicode text?</a></li>
			  <li><a href="#bom5">Can a UTF-8 data stream contain the BOM character (in UTF-8 form)? If yes, does it affect the byte order?</a></li>
			  <li><a href="#bom6">What should I do with U+FEFF in the middle of a file?</a></li>
	          <li><a href="#bom7">I am using a protocol that has BOM at the start of text. How do I represent an initial ZWNBSP?</a></li>
			  <li><a href="#bom8">How do I tag data that does not interpret U+FEFF as a BOM?</a></li>
			  <li><a href="#bom9">Why wouldn&#x2019;t I always use a protocol that requires a BOM?</a></li>
			  <li><a href="#bom10">How I should deal with BOMs?</a></li>
	        </ul>
        </div>
        <h2><a name="General"></a>General questions, relating to UTF or Encoding Form</h2>
        <p class="q"><a name="gen0"></a>Q: Is Unicode a 16-bit encoding?</p>
        <p class="a">A: No. The first version of Unicode was a 16-bit encoding, from 1991 to 1995, but starting with Unicode 2.0 (July, 1996), it has not
   been a 16-bit encoding. The Unicode Standard encodes characters in the range U+0000..U+10FFFF, which amounts to a 21-bit code space. Depending on the 
   encoding form you choose (UTF-8, UTF-16, or UTF-32), each character will then be represented either as a sequence of one to four 8-bit bytes,
   one or two 16-bit code units, or a single 32-bit code unit.</p>

		<p class="q"><a name="gen1"></a>Q: Can Unicode text be represented in more than one way?</p>   
        <p class="a">A: Yes, there are several possible representations of    
        Unicode data, including UTF-8,&nbsp; UTF-16 and UTF-32. In addition,    
        there are compression transformations such as the one described in the   
        <i><a href="http://www.unicode.org/reports/tr6/">UTS #6: A Standard Compression Scheme for Unicode</a></i> (SCSU).</p>
        <p class="q"><a name="gen2"></a>Q: What is a UTF?</p>   
        <p class="a">A: A <i>Unicode transformation format</i> (UTF) is an   
        algorithmic mapping from every Unicode code point (except surrogate code 
		points) to a unique byte   
        sequence. The ISO/IEC 10646 standard uses the term  &#x201C;UCS transformation   
        format&#x201D; for UTF; the two terms are merely synonyms for the same concept. </p>  
        <p class="a">Each UTF is reversible, thus every UTF supports <i>lossless round tripping</i>: mapping    
        from any Unicode coded character sequence S to a sequence of bytes and    
        back will produce S again. To ensure round tripping, a UTF mapping <i>   
        must</i> map all code points (except surrogate code points) to    
        unique byte sequences. This includes reserved (unassigned) code points and the 66 <a href="http://www.unicode.org/faq/private_use.html#noncharacters">noncharacters</a>  
        (including U+FFFE and U+FFFF).</p>  
        <p class="a">The <a href="http://www.unicode.org/reports/tr6/">SCSU</a>    
        compression method, even though it is reversible, is not a UTF because the same string can map to very    
        many different byte sequences, depending on the particular SCSU  
        compressor. <a href="attribution.html#AF">[AF]</a></p>
        
        <p class="q"><a name="gen3"></a>Q: Where can I get more information on    
        encoding forms?</p>   
        <p class="a">A: For the formal definition of UTFs see 
		<a href="http://www.unicode.org/versions/latest/ch03.pdf#G7404">Section 3.9, Unicode Encoding Forms</a> in <em>The Unicode Standard</em>. For more information on encoding 
		forms see <a href="http://www.unicode.org/reports/tr17/"><i>UTR #17: Unicode Character Encoding Model</i></a>.
		<a href="attribution.html#AF">[AF]</a></p>
        
        <p class="q"><a name="gen4"></a>Q: How do I write a UTF converter?</p>   
        <p class="a">A: The freely available open source project <a href="http://site.icu-project.org/">International Components for Unicode</a> (ICU) has UTF conversion built into it. The latest version may be <a href="http://site.icu-project.org/download">downloaded</a> from the ICU Project  web site. <a href="attribution.html#AF">[AF]</a></p>
<p class="q"><a name="gen8"></a>Q: Are there any byte sequences that    
  are not generated by a UTF? How should I interpret them?</p>   
        <p class="a">A: None of the UTFs can generate <i>every</i> arbitrary byte 
		sequence. For example, in UTF-8 every byte of the form 110xxxxx<i><sub>2</sub></i>
        <i>must</i> be followed with a byte of the form 10xxxxxx<i><sub>2</sub></i>. 
        A sequence such as &lt;110xxxxx<i><sub>2</sub></i> 0xxxxxxx<i><sub>2</sub></i>&gt; 
        is illegal, and must never be generated. When faced with this illegal 
        byte sequence while transforming or interpreting, a UTF-8 conformant 
        process must treat the first byte 110xxxxx<i><sub>2</sub></i> as an 
        illegal termination error: for example, either signaling an error, 
        filtering the byte out, or representing the byte with a marker such as 
        FFFD (REPLACEMENT CHARACTER). In the latter two cases, it will continue 
        processing at the second byte 0xxxxxxx<i><sub>2</sub></i>.</p>
        <p class="a">A conformant process <i>must not</i> interpret illegal or  
        ill-formed byte sequences as characters, however, it may take error 
		recovery actions. No conformant process&nbsp; may use irregular byte  
        sequences to encode out-of-band information.</p>
        
        <p class="q"><a name="gen5"></a>Q: Which of the UTFs do I need to support?</p>   
        <p class="a">A: UTF-8 is most common on the web. UTF-16 is used by Java and Windows. UTF-8 and UTF-32 
		are 
		used by Linux and various Unix systems. The conversions between all of them are 
		algorithmically based, fast and lossless. This makes it easy to support 
		data input or output in multiple formats, while using a particular UTF 
		for internal storage or processing.&nbsp; <a href="attribution.html#AF">
		[AF]</a></p>   
        
        <p class="q"><a name="gen6"></a>Q: What are some of the differences 
		between the UTFs?</p>   
        <p class="a">A: The following table summarizes some of the properties of 
		each of the UTFs.&nbsp;</p>
		<div style="font-size:80%">
		  <table class="faq" >
		    <tr>
		      <th>Name</th>
		      <th>UTF-8</th>
		      <th>UTF-16</th>
		      <th>UTF-16BE</th>
		      <th>UTF-16LE</th>
		      <th>UTF-32</th>
		      <th>UTF-32BE</th>
		      <th>UTF-32LE</th>
	        </tr>
		    <tr>
		      <th>Smallest code point</th>
		      <td align="right">0000</td>
		      <td align="right">0000</td>
		      <td align="right">0000</td>
		      <td align="right">0000</td>
		      <td align="right">0000</td>
		      <td align="right">0000</td>
		      <td align="right">0000</td>
	        </tr>
		    <tr>
		      <th>Largest code point</th>
		      <td align="right">10FFFF</td>
		      <td align="right">10FFFF</td>
		      <td align="right">10FFFF</td>
		      <td align="right">10FFFF</td>
		      <td align="right">10FFFF</td>
		      <td align="right">10FFFF</td>
		      <td align="right">10FFFF</td>
	        </tr>
		    <tr>
		      <th>Code unit size</th>
		      <td align="center">8 bits</td>
		      <td align="center">16 bits</td>
		      <td align="center">16 bits</td>
		      <td align="center">16 bits</td>
		      <td align="center">32 bits</td>
		      <td align="center">32 bits</td>
		      <td align="center">32 bits</td>
	        </tr>
		    <tr>
		      <th>Byte order</th>
		      <td align="center">N/A</td>
		      <td align="center">&lt;BOM&gt;</td>
		      <td align="center">big-endian</td>
		      <td align="center">little-endian</td>
		      <td align="center">&lt;BOM&gt;</td>
		      <td align="center">big-endian</td>
		      <td align="center">little-endian</td>
	        </tr>
		    <tr>
		      <th>Fewest bytes per character</th>
		      <td align="center">1</td>
		      <td align="center">2</td>
		      <td align="center">2</td>
		      <td align="center">2</td>
		      <td align="center">4</td>
		      <td align="center">4</td>
		      <td align="center">4</td>
	        </tr>
		    <tr>
		      <th>Most bytes per character</th>
		      <td align="center">4</td>
		      <td align="center">4</td>
		      <td align="center">4</td>
		      <td align="center">4</td>
		      <td align="center">4</td>
		      <td align="center">4</td>
		      <td align="center">4</td>
	        </tr>
	      </table>
	      </div>
		<p class="a">In the table &lt;BOM&gt; indicates that the byte order is 
		determined by a byte order mark, if present at the beginning of the data 
		stream, otherwise it is big-endian.&nbsp;<a href="attribution.html#AF">[AF]</a></p>   
        
        <p class="q"><a name="gen7"></a>Q: Why do some of the UTFs have a BE or LE 
		in their label, such as UTF-16LE?</p>
		<p class="a">A: UTF-16 and UTF-32 use code units that are two and four 
		bytes long respectively. For these UTFs, there are three sub-flavors: 
		BE, LE and unmarked. The BE form uses big-endian byte serialization 
		(most significant byte first), the LE form uses little-endian byte 
		serialization (least significant byte first) and the unmarked form uses 
		big-endian byte serialization by default, but may include a byte order 
		mark at the beginning to indicate the actual byte serialization used. <a href="attribution.html#AF">[AF]</a> </p>
		
        <p class="q"><a name="gen9"></a>Q: Is there a standard method to package a 
		Unicode character so it fits an 8-Bit ASCII stream?</p>
		<p class="a">A: There are three or four options for making Unicode fit into 
		an 8-bit format.</p>
		<p class="a">a) Use UTF-8. This preserves ASCII, but not Latin-1, 
		because the characters &gt;127 are different from Latin-1. UTF-8 uses 
		the bytes in the ASCII only for ASCII characters. Therefore, it works 
		well in any environment where ASCII characters have a significance as 
		syntax characters, e.g. file name syntaxes, markup languages, etc., but 
		where the all other characters may use arbitrary bytes. <br>
		<u>Example</u>: “Latin Small Letter s with Acute” (015B) would be 
		encoded as two bytes: C5 9B.</p>
		<p class="a">b) Use Java or C style escapes, of the form \uXXXXX or \xXXXXX. 
		This format is not standard for text files, but well defined in the 
		framework of the languages in question, primarily for source files.<br>
		<u>Example</u>: The Polish word “wyjście” with character “Latin Small 
		Letter s with Acute” (015B) in the middle (ś is one character) would 
		look like: “wyj\u015Bcie&quot;.</p>
		<p class="a">c) Use the <code>&amp;#xXXXX;</code> or <code>&amp;#DDDDD;</code> numeric character escapes 
		as in HTML or XML. Again, these are not standard for plain text files, 
		but well defined within the framework of these markup languages.<br>
		<u>Example</u>: “wyjście” would look like “<code>wyj&amp;#x015B;cie</code>&quot;</p>
		<p class="a">d) Use <a href="http://www.unicode.org/reports/tr6/">SCSU</a>. 
		This format compresses Unicode into 8-bit format, preserving most of 
		ASCII, but using some of the control codes as commands for the decoder. 
		However, while ASCII text will look like ASCII text after being encoded 
		in SCSU, other characters may occasionally be encoded with the same byte 
		values, making SCSU unsuitable for 8-bit channels that blindly interpret 
		any of the bytes as ASCII characters.<br>
		<u>Example</u>: “&lt;SC2&gt; wyjÛcie” where &lt;SC2&gt; indicates the byte 0x12 and 
		“Û” corresponds to byte 0xDB. <a href="attribution.html#AF">[AF]</a></p>
		
		<p class="q"><a name="gen10"></a>Q: Which of these approaches is the best?</p>   
        <p class="a">A: That depends on the circumstances: Of these four  
        approaches, d) uses the least space, but cannot be used <i>transparently</i> in most 8-bit environments. a) is the most widely supported in  
        plain text files and b) and c) use the most space, but are widely  
        supported for program source files in Java and C, or <i>within</i> HTML and XML files respectively.&nbsp; 
        <a href="attribution.html#AF">[AF]</a></p>
        
        <p class="q"><a name="gen11"></a>Q: Which of these formats is the most standard? </p>
        <p class="a">A: All four require that the receiver can understand that  
        format, but a) is considered one of the three equivalent Unicode  
        Encoding Forms and therefore standard. The use of b), or c) out of their  
        given context would definitely be considered non-standard, but could be  
        a good solution for internal data transmission. The use of SCSU is  
        itself a standard (for compressed data streams) but few general purpose  
        receivers support SCSU, so it is again most useful in internal data  
        transmission. <a href="attribution.html#AF">[AF]</a></p>
		<h2><a name="UTF8"></a>UTF-8 FAQ</h2>
        
		<p class="q"><a name="utf8-1"></a>Q: What is the definition of UTF-8?</p>   
        <p class="a">A: UTF-8 is the byte-oriented encoding form of Unicode. For 
        details of its definition, see <a href="http://www.unicode.org/versions/latest/ch02.pdf#G13708">Section 2.5, Encoding Forms</a> and <a href="http://www.unicode.org/versions/latest/ch03.pdf#G7404">Section 
        3.9, Unicode Encoding Forms</a> &#x201D; in <em>The Unicode Standard</em>. See, in particular, Table 3-6 <i>UTF-8 Bit Distribution</i> 
        and Table 3-7 <i>Well-formed UTF-8 Byte Sequences</i>, which give 
		succinct summaries of the encoding form. Make sure you refer to the latest version of the 
		Unicode Standard, as the <a href="http://www.unicode.org/consortium/utc.html">   
        Unicode Technical Committee</a> has tightened the definition of UTF-8  
        over time to more strictly enforce unique sequences and to prohibit  
        encoding of certain invalid characters. There is an Internet 
		<a href="http://www.ietf.org/rfc/rfc3629.txt">RFC 3629</a>  
        about UTF-8. UTF-8 is also defined in Annex D of ISO/IEC 10646. See also 
		the question above, <a href="#gen4">How do I write a UTF converter?</a></p>   
        
        <p class="q"><a name="utf8-2"></a>Q: Is the UTF-8 encoding scheme the same    
        irrespective of whether the underlying processor is little endian or big    
        endian?</p>
        <p class="a">A: Yes. Since UTF-8 is interpreted as a sequence of bytes,  
        there is no endian problem as there is for encoding forms that use  
        16-bit or 32-bit code units. Where a BOM is used with UTF-8, it is <i> 
        only</i> used as an encoding signature to distinguish UTF-8 from other encodings — it has nothing  
        to do with byte order.&nbsp; 
        <a href="attribution.html#AF">[AF]</a></p> 
        <p class="q"><a name="utf8-3"></a>Q: Is the UTF-8 encoding scheme the same    
        irrespective of whether the underlying system uses ASCII or EBCDIC    
        encoding?</p>
        <p class="a">A: There is only one definition of UTF-8. It is precisely the same, 
		whether the data were converted from ASCII or EBCDIC based character 
		sets. However, byte sequences from standard UTF-8 won&#x2019;t interoperate 
		well in an EBCDIC system, because of the different arrangements of 
		control codes between ASCII and EBCDIC.
		<a href="http://www.unicode.org/reports/tr16/"><em>UTR #16:
		UTF-EBCDIC</em></a> defines is a specialized UTF&nbsp; that will 
		interoperate in EBCDIC systems. 
        <a href="attribution.html#AF">[AF]</a></p>
        
        <p class="q"><a name="utf8-4"></a>Q: How do I convert a UTF-16 surrogate 
		pair such as &lt;D800 DC00&gt; to UTF-8? As one 4-byte sequence or as two 
		separate 3-byte sequences?</p>   
        <p class="a">A: The definition of UTF-8 requires that supplementary 
		characters (those using surrogate pairs in UTF-16) be encoded with a 
		single 4-byte sequence. However, there is a widespread practice of generating 
		pairs of 3-byte sequences in older software, especially software which pre-dates the    
        introduction of UTF-16 or that is interoperating with UTF-16 
		environments under particular constraints. Such an encoding is <i>not conformant</i>    
        to UTF-8 as defined. See <a href="http://www.unicode.org/reports/tr26/"><em>UTR    
        #26: Compatability Encoding Scheme for UTF-16: 8-bit (CESU)</em></a> for a 
		formal description of such a non-UTF-8 data format. When using CESU-8, 
		great care must be taken that data is not accidentally treated as if it 
		was UTF-8, due to the similarity of the formats.   
        <a href="attribution.html#AF">[AF]</a></p>
        
        <p class="q"><a name="utf8-5"></a>Q: How do I convert an unpaired UTF-16 surrogate 
		to UTF-8? </p>   
		<p class="a">A different issue arises if an <i>unpaired</i> surrogate is 
		encountered when converting ill-formed UTF-16 data. By representing such 
		an unpaired surrogate on its own as 
		a 3-byte sequence, the resulting UTF-8 data stream would become 
		ill-formed. While it faithfully reflects the nature of the input, 
		Unicode conformance requires that encoding form conversion always 
		results in a valid data stream. Therefore a converter<i> must</i> treat 
		this as an error. <a href="attribution.html#AF">[AF]</a></p>
        
		<h2><a name="UTF16"></a>UTF-16 FAQ</h2>
		<p class="q"><a name="utf16-1"></a>Q: What is UTF-16?</p>   
        <p class="a">A: UTF-16 uses a single 16-bit code unit to encode the most 
		common 63K characters, and a pair of 16-bit code units, called 
		surrogates, to encode the 1M less commonly used characters in Unicode.</p>
		<p class="a">Originally, Unicode was designed as a pure 16-bit 
        encoding, aimed at representing all modern scripts. (Ancient scripts 
        were to be represented with private-use characters.) Over time, and 
        especially after the addition of over 14,500 composite characters for 
        compatibility with legacy sets, it became clear that 16-bits were not 
        sufficient for the user community. Out of this arose UTF-16. 
        <a href="attribution.html#AF">[AF]</a></p>
		<p class="q"><a name="utf16-2"></a>Q: What are surrogates?</p>
		<p class="a">A: Surrogates are code points from two special ranges of Unicode 
		values, reserved  
        for use as the leading, and trailing values of paired code units 
		in UTF-16. Leading, also called high, surrogates are  
        from D800<sub>16</sub> to DBFF<sub>16</sub>, and trailing, or low, 
		surrogates are from DC00<sub>16</sub> to DFFF<sub>16</sub>. They are called 
		surrogates, since they do not represent characters directly, but only as a 
		pair.</p>
        
<p class="q"><a name="utf16-3"></a>Q: What&#x2019;s the algorithm to convert from   
        UTF-16 to character codes?</p>  
        <p class="a">A: The Unicode Standard used to contain a short algorithm,  
        now there is just a bit distribution table. Here are three short code snippets 
        that translate the information from the bit distribution table into C 
        code that will convert to and from UTF-16. </p>
		<p class="a">Using the following type definitions</p>
		<blockquote>
			<pre class="a">typedef unsigned int16 UTF16;
typedef unsigned int32 UTF32;</pre>
		</blockquote>
		<p class="a">the first snippet calculates 
        the high (or leading) surrogate from a character code C.</p>
        <blockquote>
        <pre class="a">const UTF16 HI_SURROGATE_START = 0xD800</pre>
        <pre class="a">UTF16 X = (UTF16) C;
UTF32 U = (C &gt;&gt; 16) &amp; ((1 &lt;&lt; 5) - 1);
UTF16 W = (UTF16) U - 1;
UTF16 HiSurrogate = HI_SURROGATE_START | (W &lt;&lt; 6) | X &gt;&gt; 10;
</pre>
        </blockquote>
        <p  class="a">where X, U and W correspond to the labels used in Table 
		3-5 <i>UTF-16 Bit Distribution</i>. The next snippet does the same for the low surrogate.</p>
        <blockquote>
        <pre class="a">const UTF16 LO_SURROGATE_START = 0xDC00</pre>
        <pre class="a">UTF16 X = (UTF16) C;
UTF16 LoSurrogate = (UTF16) (LO_SURROGATE_START | X &amp; ((1 &lt;&lt; 10) - 1));</pre>
        </blockquote>
<p  class="a">Finally, the reverse, where hi and lo are the high and low 
surrogate, and C the resulting character</p>
        <blockquote>
        <pre class="a">UTF32 X = (hi &amp; ((1 &lt;&lt; 6) -1)) &lt;&lt; 10 | lo &amp; ((1 &lt;&lt; 10) -1);
UTF32 W = (hi &gt;&gt; 6) &amp; ((1 &lt;&lt; 5) - 1);
UTF32 U = W + 1;</pre>
        <pre class="a">UTF32 C = U &lt;&lt; 16 | X;</pre>
        </blockquote>
        <p class="a">A caller would need to ensure that C, hi, and lo are in the 
        appropriate ranges. <a href="attribution.html#AF">[AF]</a> </p>
		<p class="q"><a name="utf16-4"></a>Q: Isn&#x2019;t there a simpler way to do this?</p>
		<p class="a">A: There is a much simpler computation that does not try to 
		follow the bit distribution table.</p>
		<blockquote>
			<pre class="a">// constants
const UTF32 LEAD_OFFSET = 0xD800 - (0x10000 &gt;&gt; 10);
const UTF32 SURROGATE_OFFSET = 0x10000 - (0xD800 &lt;&lt; 10) - 0xDC00;

// computations
UTF16 lead = LEAD_OFFSET + (codepoint &gt;&gt; 10);
UTF16 trail = 0xDC00 + (codepoint &amp; 0x3FF);

UTF32 codepoint = (lead &lt;&lt; 10) + trail + SURROGATE_OFFSET;</pre>
		</blockquote>
    	<p class="a"><a href="attribution.html#MD">[MD]</a></p>
        <p class="q"><a name="utf16-5"></a>Q: Why are some people opposed to UTF-16?</p>   
        <p class="a">A: People familiar with variable width East Asian character 
		sets such as Shift-JIS ( SJIS) are understandably nervous about UTF-16, 
		which sometimes requires two code units to represent a single character. 
		They are well acquainted with the problems that variable-width 
		codes have caused.  
        However, there are some important differences between the mechanisms 
		used in SJIS and UTF-16: 
        </p>
        <p class="a">Overlap: </p>
		<ul>
			<li>
			<p class="a">In SJIS, there is overlap between the leading and 
			trailing code unit values, and between the trailing and single code unit values. This causes a number of problems:
			<ul>
				<li>
				<p class="a">It causes false matches. For example, searching for 
              an &#x201C;a&#x201D; may match against the trailing code unit of a Japanese character.
				</li>
				<li>
				<p class="a">It prevents efficient random access. To know whether 
              you are on a character boundary, you have to search backwards to 
              find a known boundary. </li>
				<li>
				<p class="a">It makes the text extremely fragile. If a unit is 
              dropped from a leading-trailing code unit pair, many following characters can be 
              corrupted.</li>
			</ul></li>
			<li>
			<p class="a">In UTF-16, the code point ranges for high and low 
			surrogates, as well as for single units are all completely disjoint.
			None of these problems occur:<ul>
			<li>
			<p class="a">There are no false matches.</p></li>
			<li>
			<p class="a">The location of the character boundary can be directly 
			determined from each code unit value.</p></li>
			<li>
			<p class="a">A dropped surrogate will corrupt only a single 
			character.</p></li>
			</ul>
			</li>
		</ul>
		<p class="a">Frequency: </p>
		<ul>
			<li>
			<p class="a">The vast majority of SJIS characters require 2 units, 
			but characters using single units occur commonly and often have 
			special importance, for example in file names.</li>
			<li>
			<p class="a">With UTF-16, relatively few characters require 2 units.  
            The vast majority of characters in common use are single code units.  
            Even in East Asian text, the incidence of surrogate pairs should be  
            well less than 1% of all text storage on average. (Certain  
            documents, of course, may have a higher incidence of surrogate  
            pairs, just as <i>phthisique</i> is an fairly infrequent word in  
            English, but may occur quite often in a particular scholarly text.) 
          <a href="attribution.html#AF">[AF]</a></li>
		</ul>
        <p class="q"><a name="utf16-6"></a>Q: Will UTF-16 ever be extended to more    
        than a million characters?</p>   
        <p class="a">A: No. Both Unicode and ISO 10646 have    
        policies in place that formally limit future code assignment to    
        the integer range that can be expressed with current UTF-16 (0 to 
		1,114,111). Even if other encoding forms (i.e. other UTFs) can represent 
		larger integers, these policies mean that all encoding forms will 
		always represent the same set of characters. Over a million possible codes is far more than enough    
        for the goal of Unicode of encoding characters, not glyphs. Unicode is <i>not</i> designed to encode arbitrary data. If    
        you wanted, for example, to give each  &#x201C;instance of a character on paper    
        throughout history&#x201D; its own code, you might need trillions or    
        quadrillions of such codes; noble as this effort might be, you would not    
        use Unicode for such an encoding.&nbsp;<a href="attribution.html#AF">[AF]</a></p>
        <p class="q"><a name="utf16-7"></a>Q: Are there any 16-bit values that are 
		invalid?</p>
		<p class="a">A: Unpaired surrogates are invalid in UTFs. These include any value 
		in the range D800<sub>16</sub> to DBFF<sub>16</sub> not followed by a value in the range DC00<sub>16</sub> 
		to DFFF<sub>16</sub>, or any value in the range DC00<sub>16</sub> to DFFF<sub>16</sub> not preceded by a 
		value in the range D800<sub>16</sub> to DBFF<sub>16</sub>. <a href="attribution.html#AF">[AF]</a></p>
		<p class="q"><a name="utf16-8"></a>Q: What about noncharacters? Are they invalid?</p>   
        <p class="a">A: Not at all. Noncharacters are valid in UTFs and must be properly converted.
        For more details on the definition and use of noncharacters, as well as their correct representation in each UTF,
        see the <a href="http://www.unicode.org/faq/private_use.html#noncharacters">Noncharacters FAQ</a>.</p>
        <p class="q"><a name="utf16-9"></a>Q: Because most supplementary characters are uncommon, does that mean I can ignore them?</p>   
        <p class="a">A: Most supplementary characters (expressed with surrogate pairs in 
UTF-16) are not too common. However, that does <i>not</i> mean that 
supplementary characters should be neglected. Among them are a number of 
individual characters that are very popular, as well as many sets 
important to East Asian procurement specifications. Among the notable 
supplementary characters are:</p>
        <ul>
<li><p class="a">many popular emoji and emoticons</p></li>
<li><p class="a">symbols used for interoperating with Wingdings and Webdings</p></li>
<li><p class="a">numerous small sets of CJK characters important for procurement, including personal and place names</p></li>
<li><p class="a">variation selectors used for all ideographic variation sequences</p></li>
<li><p class="a">numerous minority scripts important for some user communities</p></li>
<li><p class="a">some highly salient historic scripts, such as Egyptian hieroglyphics </p></li>
	</ul>
<p class="a">Ken Lunde has an interesting presentation file on this topic, with a <a href="https://blogs.adobe.com/CCJKType/files/2016/11/top-ten-lists-2016.pdf">Top Ten list: Why Support Beyond-BMP Code Points?</a></p>
        <p class="q"><a name="utf16-10"></a>Q: How should I handle supplementary characters in my code?</p>
        <p class="a">A: Compared with BMP characters as a whole, the supplementary characters 
  occur less commonly in text. This remains true now, even though many 
  thousands of supplementary characters have been added to the standard, 
  and a few individual characters, such as popular emoji, have become 
  quite common. The relative frequency of BMP characters, and of 
  the ASCII subset within the BMP, <i>can</i> be taken into account when 
  optimizing implementations for best performance: execution speed, memory 
  usage, and data storage.</p>
<p class="a">Such strategies are particularly useful for UTF-16 implementations, 
          where BMP characters require one 16-bit code unit to process or store, 
          whereas supplementary characters require two.          </p>
        <p class="a">Strategies that optimize for the BMP are less useful for UTF-8 
          implementations, but if the distribution of data warrants it, an 
          optimization for the ASCII subset may make sense, as that subset only 
          requires a single byte for processing and storage in UTF-8. </p>


      <p class="q"><a name="utf16-11"></a>Q: What is the difference between UCS-2 and UTF-16?</p>
      <p class="a">A: UCS-2 is obsolete terminology which refers to a Unicode implementation up to Unicode 1.1, <i>before</i> surrogate code points and UTF-16 were added to Version 2.0 of the standard. This term should now be avoided.</p>
		<p class="a">UCS-2 does not describe a data format distinct from UTF-16, because
both use exactly the same 16-bit code unit representations. However,
UCS-2 does not <i>interpret</i> surrogate code points, and thus
cannot be used to conformantly represent supplementary characters.</p>
		<p class="a">Sometimes in the past an implementation has been labeled &quot;UCS-2&quot; to indicate that it does not support supplementary characters and doesn't interpret pairs of surrogate code points as characters. Such an implementation would not handle processing of character properties, code point boundaries, collation, etc. for supplementary characters. <a href="http://www.unicode.org/faq/attribution.html#AF">[AF]</a></p>




        <h2><a name="UTF32"></a>UTF-32 FAQ</h2>
		<p class="q"><a name="utf32-1"></a>Q: What is UTF-32?</p>
        <p class="a">A: Any Unicode character can be  
        represented as a single 32-bit unit in UTF-32. This single 4 code unit  
        corresponds to the Unicode scalar value, which is the abstract number  
        associated with a Unicode character. UTF-32 is a subset of the encoding  
        mechanism called <i>UCS-4</i> in ISO 10646. For more information, see <a href="http://www.unicode.org/versions/latest/ch03.pdf#G7404">Section 3.9, Unicode Encoding Forms</a> in <em>The Unicode Standard</em><i>.</i> 
        <a href="attribution.html#AF">[AF]</a></p>
        
		<p class="q"><a name="utf32-2"></a>Q: Should I use UTF-32 (or UCS-4) for    
        storing Unicode strings in memory?</p>   
        <p class="a">A: This depends. If you frequently need to access APIs that 
		require string parameters to be in UTF-32, it may be more convenient to 
		work with UTF-32 strings all the time. However, the downside of UTF-32 
		is that it forces you to use 32-bits for each character, when only 21 
		bits are ever needed. The number of significant bits needed for the 
		average character in common texts is much lower, making the ratio 
		effectively that much worse. In many situations that does not matter, 
		and the convenience of having a fixed number of code units per character 
		can be the deciding factor. </p>
		<p class="a">Increasing the storage for the same 
		number of characters does have its cost in applications dealing with 
		large volume of text data: it can mean exhausting cache limits sooner; 
		it can result in noticeably increased read/write times or in reaching 
		bandwidth limits; and it requires more space for storage. What a number of implementations do is to represent strings with 
			UTF-16,	but individual character values with 
		UTF-32. </p>
		<p class="a">The chief selling point for Unicode is providing a 
        representation for all the world&#x2019;s characters, eliminating the need for 
        juggling multiple character sets and avoiding the associated data corruption 
        problems. These features were enough to swing industry to the side of 
        using Unicode (UTF-16). While a UTF-32 representation does make the 
        programming model somewhat simpler, the increased average storage size 
		has real drawbacks, making a complete transition to UTF-32 less compelling. <a href="attribution.html#AF">
		[AF]</a></p>
		<p class="q"><a name="utf32-3"></a>Q: How about using UTF-32 interfaces in my    
        APIs?</p>
        <p class="a">A: Except in some environments that store text as UTF-32 in 
		memory, most Unicode APIs are using UTF-16. With UTF-16 APIs&nbsp; the 
		low level  
        indexing is at the storage or code unit level, with higher-level mechanisms  
        for graphemes or words specifying their boundaries in terms of the  
        code units. This provides efficiency at the low levels, and the  
        required functionality at the high levels.</p>
		<p class="a">If its ever necessary to locate the <i>n</i><sup>th </sup>
		character, indexing by character can be implemented as a high level 
		operation. However, while converting  
        from such a UTF-16 code unit index to a character index or vice versa is fairly  
        straightforward, it does involve a scan through the 16-bit units up to  
        the index point. In a test run, for example, accessing UTF-16 storage as 
        characters, instead of code units resulted in a 10× degradation. While 
		there are some interesting optimizations that can be performed, it will 
		always be slower on average. Therefore locating other boundaries, such 
		as grapheme, word, line or sentence boundaries proceeds directly from 
		the code unit index, not indirectly via an intermediate character code 
		index.</p>
        <p class="q"><a name="utf32-4"></a>Q: Doesn&#x2019;t it cause a problem to have    
        only UTF-16 string APIs, instead of UTF-32 char APIs?</p>   
        <p class="a">A: Almost all international functions (upper-, lower-, 
        titlecasing, case folding, drawing, measuring, collation, 
        transliteration, grapheme-, word-, linebreaks, etc.) should take <i>
        string parameters</i> in the API, <b><i>not</i></b> single code-points 
		(UTF-32). Single code-point APIs almost always produce the wrong results 
		except for very 
        simple languages, either because you need more context to get the right answer, 
        or because you need to generate a sequence of characters to return 
        the right answer, or both. </p>
		<p class="a">For example, any Unicode-compliant 
        collation (See<em> <a href="http://www.unicode.org/reports/tr10/">UTS #10: Unicode Collation Algogrithm (UCA)</a></em>) must be able to handle sequences of more than one 
        code-point, and treat that sequence as a single entity. Trying to collate by handling single code-points  
        at a time, would get the wrong answer. The same will happen for drawing 
		or measuring text a single code-point at a time; because scripts like  
        Arabic are contextual, the width of <i>x</i> plus the width of <i>y</i> is not equal  
        to the width of <i>xy</i>. Once you get beyond basic typography, the same is  
        true for English as well; because of kerning and ligatures the width of  
         &#x201C;fi&#x201D; in the font may be different than the width of  &#x201C;f&#x201D; plus the width  
        of  &#x201C;i&quot;. Casing operations must return strings, not single code-points;  
        see <a href="http://www.unicode.org/charts/case/"> 
        http://www.unicode.org/charts/case/</a> . In particular, the title  
        casing operation requires strings as input, not single code-points at a  
        time.</p>
        <p class="a">Storing a single code point 
        in a struct or class instead of a string, would exclude support for 
        graphemes, such as “ch” for Slovak, where a single code point may not be sufficient, 
		but a character sequence is needed to express what 
        is required. In other words, most API parameters and fields of composite 
		data types should
        <i>not</i> be defined as a character, but as a string. And if they are 
		strings, it does not matter what the internal representation of the 
		string is.</p>
		<p class="a">Given that any industrial-strength text and 
		internationalization support API has to be able to handle sequences of 
		characters, it makes 
		little difference whether the string is internally represented by a 
		sequence of UTF-16 code units, or by a sequence of code-points ( = UTF-32 code units). 
		Both UTF-16 and UTF-8 are designed to make working with substrings easy, 
		by the fact that the sequence of code units for a given code point is 
		unique. <a href="attribution.html#AF">[AF]</a></p>
		<p class="q"><a name="utf32-5"></a>Q: Are there exceptions to the rule of exclusively using 
		string parameters in APIs?</p>
        <p class="a">A: The main exception are very low-level    
        operations such as getting character properties (e.g. General Category    
        or Canonical Class in the UCD). For those it is handy to have interfaces 
		that convert quickly to and from UTF-16 and UTF-32, and that allow you 
		to iterate through strings returning UTF-32 values (even though the 
		internal format is UTF-16).</p>
        <p class="q"><a name="utf32-6"></a>Q: How do I convert a UTF-16 surrogate 
		pair such as &lt;D800 DC00&gt; to UTF-32? As one 4-byte sequence or as two 
		4-byte sequences?</p>   
        <p class="a">A: The definition of UTF-32 requires that supplementary 
		characters (those using surrogate pairs in UTF-16) be encoded with a 
		single 4-byte sequence.</p>
        
        <p class="q"><a name="utf32-7"></a>Q: How do I convert an unpaired UTF-16 surrogate 
		to UTF-32? </p>   
		<p class="a">A: If an <i>unpaired</i> surrogate is encountered when 
		converting ill-formed UTF-16 data, any conformant converter<i> must</i> 
		treat this as an error. By representing such an unpaired surrogate on its 
		own, the resulting UTF-32 data stream would become ill-formed. While it 
		faithfully reflects the nature of the input, Unicode conformance 
		requires that encoding form conversion always results in valid data 
		stream. <a href="attribution.html#AF">[AF]</a></p>
        
		<h2><a name="BOM"></a>Byte Order Mark (BOM) FAQ</h2>
        
		<p class="q"><a name="bom1"></a>Q: What is a BOM?</p>   
        <p class="a">A: A <i>byte order mark </i>(BOM) consists of the character 
        code U+FEFF at the beginning of a data stream, where it can be used  
        as a signature defining the byte order and encoding form, primarily of unmarked plaintext 
        files. Under some higher level protocols, use of a BOM may be mandatory 
		(or prohibited) in the Unicode data stream defined in that 
        protocol. 
        <a href="attribution.html#AF">[AF]</a></p>
        <p class="q"><a name="bom2"></a>Q: Where is a BOM useful?</p>   
        <p class="a">A: A BOM is useful at the beginning of files that are typed as   
        text, but for which it is not known whether they are in big or little endian format—it 
		can also serve as a hint indicating that the file is in Unicode, as 
		opposed to in a legacy encoding and furthermore, it act as a signature 
		for the specific encoding form used. <a href="attribution.html#AF">[AF]</a> 
        </p>  
        <p class="q"><a name="bom3"></a>Q: What does &#x2018;endian&#x2019; mean?</p>  
        <p class="a">A: Data types longer than a byte can be stored in computer 
        memory with the most significant byte (MSB) first or last. The former is 
        called big-endian, the latter little-endian. When data is exchanged, bytes 
        that appear in the "correct" order on the sending system may appear to be 
        out of order on the receiving system. In that situation, a BOM would look 
        like 0xFFFE which is a <a href="http://www.unicode.org/faq/private_use.html#noncharacters">noncharacter</a>, allowing the receiving system to 
        apply byte reversal before processing the data. UTF-8 is byte oriented and 
        therefore does not have that issue. Nevertheless, an initial BOM might be 
        useful to identify the datastream as UTF-8. <a href="attribution.html#AF">[AF]</a> 
        </p> 
        <p class="q"><a name="bom4"></a>Q: When a BOM is used, is it only in    
        16-bit Unicode text?</p>   
        <p class="a">A: No, a BOM can be used as a signature no matter how the 
        Unicode text is transformed: UTF-16, UTF-8, or UTF-32. The exact bytes 
        comprising the BOM will be whatever the Unicode character U+FEFF is 
        converted into by that transformation format. In that form, the BOM 
        serves to indicate both that it is a Unicode file, and which of the 
        formats it is in. Examples:</p>
        <div align="center">
          <center>
          <table class="faq">
            <tr>
              <th>Bytes</th>
              <th>Encoding Form</th>
            </tr>
            <tr>
              <td>00 00 FE FF</td>
              <td>UTF-32, big-endian</td>
            </tr>
            <tr>
              <td>FF FE 00 00</td>
              <td>UTF-32, little-endian</td>
            </tr>
            <tr>
              <td>FE FF</td>
              <td>UTF-16, big-endian</td>
            </tr>
            <tr>
              <td>FF FE</td>
              <td>UTF-16, little-endian</td>
            </tr>
            <tr>
              <td>EF BB BF</td>
              <td>UTF-8</td>
            </tr>
          </table>
          </center>
        </div>
        <p class="q"><a name="bom5"></a>Q: Can a UTF-8 data stream contain the BOM    
        character (in UTF-8 form)? If yes, then can I still assume the remaining    
        UTF-8 bytes are in big-endian order?</p>
<p class="a">A: Yes, UTF-8 can contain a BOM. However, it makes <i>no</i>  
  difference as to the endianness of the byte stream. UTF-8 always has the  
  same byte order. An initial BOM is <i>only</i> used as a signature &#x2014; an  
  indication that an otherwise unmarked text file is in UTF-8. Note that 
  some recipients of UTF-8 encoded data do not expect a BOM. Where UTF-8 
  is used<i> transparently</i> in 8-bit environments, the use of a BOM 
  will interfere with any protocol or file format that expects specific 
  ASCII characters at the beginning, such as the use of &quot;#!&quot; of at the 
  beginning of Unix shell scripts.<i> </i><a href="attribution.html#AF">
    [AF]</a></p>
        <p class="q"><a name="bom6"></a>Q: What should I do with U+FEFF in the 
		middle of a file?</p>   
        <p class="a">A: In the absence of a protocol supporting its use as a BOM and when not at the   
        beginning of a text stream, U+FEFF should normally not occur. For 
		backwards compatibility it should be treated as ZERO WIDTH  
        NON-BREAKING SPACE (ZWNBSP),   
        and is then part of the content of the file or string. The use of  
        U+2060 WORD JOINER is strongly preferred over ZWNBSP for expressing word joining 
		semantics since it cannot be confused with a BOM. When designing a markup 
		language or data protocol, the use of U+FEFF can be restricted to that 
		of Byte Order Mark. In that case, any U+FEFF occurring in the middle of a file can be treated as an 
		<a href="http://www.unicode.org/faq/unsup_char.html">unsupported character</a>.&nbsp;<a href="attribution.html#AF">[AF]</a> 
        </p>
        <p class="q"><a name="bom7"></a>Q: I am using a protocol that has BOM at    
        the start of text. How do I represent an initial ZWNBSP?</p>   
        <p class="a">A: Use U+2060 WORD JOINER instead.&nbsp;</p>  
        <p class="q"><a name="bom8"></a>Q: How do I tag data that does not    
        interpret U+FEFF as a BOM?</p>   
        <p class="a">A: Use the tag <tt>UTF-16BE</tt> to indicate big-endian  
        UTF-16 text, and <tt>UTF-16LE</tt> to indicate little-endian UTF-16  
        text. If you do use a BOM, tag the text as simply <tt>UTF-16</tt>. 
        <a href="attribution.html#MD">[MD]</a></p>
        <p class="q"><a name="bom9"></a>Q: Why wouldn&#x2019;t I always use a protocol    
        that requires a BOM?</p>   
        <p class="a">A: Where the data has an associated type, such as a field in a database,  
        a BOM is unnecessary. In particular, if a text data stream is marked as  
        UTF-16BE, UTF-16LE, UTF-32BE or UTF-32LE, a BOM is neither necessary nor <i>permitted</i>. 
		Any U+FEFF would be interpreted as a ZWNBSP.</p>
		<p class="a">Do not tag every string in a database or set of fields with a BOM, 
		since it wastes space and complicates string concatenation. Moreover, it also means two data fields may have  
        precisely the same content, but not be binary-equal (where one is  
        prefaced by a BOM).</p> 
        <p class="q"><a name="bom10"></a>Q: How I should deal    
        with BOMs?</p>   
        <p class="a">A: Here are some guidelines to follow: </p>
        <ol>
          <li>
          <p class="a">A particular protocol (e.g. Microsoft conventions for 
          .txt files) may require use of the BOM on certain Unicode data 
          streams, such as files. When you need to conform to such a protocol, 
          use a BOM. </li>
          <li>
          <p class="a">Some protocols allow optional BOMs in the case of 
          untagged text. In those cases,
          <ul>
            <li>
            <p class="a">Where a text data stream is known to be plain text, but 
            of unknown encoding, BOM can be used as a signature. If there is no 
            BOM, the encoding could be anything.</li>
            <li>
            <p class="a">Where a text data stream is known to be plain Unicode 
            text (but not which endian), then BOM can be used as a signature. If 
            there is no BOM, the text should be interpreted as big-endian.</li>
          </ul>
          </li>
          <li>
			<p class="a">Some byte oriented protocols expect ASCII characters at 
			the beginning of a file. If UTF-8 is used with these protocols, use 
			of the BOM as encoding form signature should be avoided.</li>
          <li>
          <p class="a">Where the precise type of the data stream is known (e.g.  
          Unicode big-endian or Unicode little-endian), the BOM should not be  
          used. In particular, whenever a data stream is declared to be 
			UTF-16BE, UTF-16LE, UTF-32BE or UTF-32LE a BOM <i>must</i> not be 
			used. (See also <a href="http://unicode.org/faq/utf_bom.html#utf16-11">Q: What is the 
			difference between UCS-2 and UTF-16?</a>.)
		  <a href="attribution.html#AF">[AF]</a></li> 
        </ol>
        
        <p class="a">&nbsp;</p>
        <hr width="50%">
        <div align="center">
          <center>
          <table cellspacing="0" cellpadding="0" border="0">
            <tr>
              <td><a href="http://www.unicode.org/copyright.html">
              <img src="http://www.unicode.org/img/hb_notice.gif" border="0" 
              alt="Access to Copyright and terms of use" width="216" 
              height="50"></a></td>
            </tr>
          </table>
          <script language="Javascript" type="text/javascript" 
          src="http://www.unicode.org/webscripts/lastModified.js"></script>
          </center>
        </div>
      </blockquote>
      </td>
    </tr>
  </table>
</body>

</html>
